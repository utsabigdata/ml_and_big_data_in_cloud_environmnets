{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data into Elasticsearch\n",
    "\n",
    "### Elasticsearch can obtain data from multible sources. The information can be delivered by Logstash (A pipeline and Preprocessing Engine) or directly using Elasticsearch API.\n",
    "\n",
    "### In this notebook we will present a simple example for uploading CSV files.\n",
    "<img src=\"img/es_data_collection.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Python PIP\n",
    "\n",
    "##### Python pip is the standard package-manager for installing and managing software packages for pythom. Since we are using Python 3, we will install pip3 using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo apt install -y python3-pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, we will use python pip to install the following 3 libraries:\n",
    "\n",
    "* elasticsearch-loader: Used for uploading daata to elasticsearch.\n",
    "* elasticsearch: Used for querying elasticsearch.\n",
    "* elasticsearch_dsl: A high-level library built on top of elasticsearch-py for writting and running queries against elasticsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip3 install --user elasticsearch-loader\n",
    "pip3 install --user elasticsearch\n",
    "pip3 install --user elasticsearch_dsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Pandas\n",
    "\n",
    "##### Pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip3 install --user pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the installed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import elasticsearch\n",
    "import csv\n",
    "import pandas as pd\n",
    "from elasticsearch_dsl import Search\n",
    "from elasticsearch_dsl import Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We use \"elasticsearch_loader\" to communicate with our elasticsearch cluster and upload the file \"students.csv\". Before you run, make sure you replace \"gtp860219\" placed after \"csv-itesm-\" with your initials and any \"YYMMDD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/ubuntu/ml_and_big_data_in_cloud_environmnets\n",
    "elasticsearch_loader --es-host <ELASTICSEARCH-IP-ADDRESS>:9200 \\\n",
    "    --http-auth logstash_internal:elasticsiem \\\n",
    "    --index csv-itesm-gtp860219 \\\n",
    "    --type student-records csv /home/ubuntu/ml_and_big_data_in_cloud_environmnets/files/students.csv    \n",
    "\n",
    "# %%bash\n",
    "# cd /home/ubuntu/ml_and_big_data_in_cloud_environmnets\n",
    "# elasticsearch_loader --es-host 10.1.1.18:9200 \\\n",
    "#     --http-auth logstash_internal:elasticsiem \\\n",
    "#     --index test-ml \\\n",
    "#     --type airline-records csv /home/ubuntu/ml_and_big_data_in_cloud_environmnets/workshop_aug_2019/files/airline-passengers.csv    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an Elasticsearch Query\n",
    "##### Let us collect the data that we have uploaded to elastic search by communicating with it's API. We start by connecting to the Elasticsearch node using our credentials.\n",
    "##### Next, we define our query using the \"Search\" command.\n",
    "##### Finally we print the total number of records matching the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = elasticsearch.Elasticsearch([\"elastic:elasticsiem@localhost:9200\"])\n",
    "#res = Search(using=es, index=\"csv-itesm*\").query(\"match\", username=\"Erin\")\n",
    "#res = Search(using=es, index=\"csv-itesm*\")\\\n",
    "#        .query('bool', filter=Q('exists', field='name') & Q('exists', field='major'))\n",
    "\n",
    "# Print all records matching the index csv-itesm where the name is Erin\n",
    "res = Search(using=es, index=\"csv-itesm*\").query(\"match\", major=\"Engineering\")\n",
    "response = res.execute()\n",
    "print(response)\n",
    "\n",
    "# Let us print the number of records obtained\n",
    "print(\"Total number of logs: %d \\n\" %(response.hits.total.value))\n",
    "\n",
    "# Print All resords matching the index csv-itesm\n",
    "res = Search(using=es, index=\"csv-itesm*\")\n",
    "response = res.execute()\n",
    "print(response)\n",
    "\n",
    "# Let us print the number of records obtained\n",
    "print(\"Total number of logs: %d \\n\" %(response.hits.total.value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump queried information into a dataframe.\n",
    "##### First, we will create a Dataframe to place the collected data. Each matched document in the query can be retrieved using the \"hit\" paramenter. Scanning through each hit and defining the key that we want to retrieve is the approach we use for collecting and storing data in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_df = pd.DataFrame(((hit[\"\\ufeffname\"],hit['major']) for hit in res.scan()),\\\n",
    "                    columns=['name','major'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the first values in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
