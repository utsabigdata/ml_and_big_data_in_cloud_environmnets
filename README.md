<img align="right" height="70" src="https://github.com/utsabigdata/ml_and_big_data_in_cloud_environmnets/blob/master/img/chameleon.jpg">


<br /><br /><br />

# Machine Learning and Big Data Analytics in Cloud Environments

### Instructor: Gonzalo De La Torre Parra

### Workshop Attendance: UTSA Students and Faculty Members

## Course Materials:
* [Jupyter Notebooks](https://github.com/utsabigdata/ml_and_big_data_in_cloud_environmnets)

#### Summary: This 3 hour work shop will cover introductory topics such as introduction to data analytics in the cloud, distributed data repositories, deploying your own data analytics and machine learning environment, deriving structure from unstructured data, querying and filtering your data, data visualization, and machine learning.

## Topics

* Introduction to Chameleon Cloud

In this section we will introduce students and faculty members to Chameleon Cloud, an NSF-funded testbed system for Computer Science experimentation. It is designed to be deeply reconfigurable, with a wide variety of capabilities for researching systems, networking, distributed and cluster computing and security. 

* Introduction to Data Analytics in the Cloud and Distributed Data Reporitories

In this section we introduce big data concepts and characteristics along with data manipulation and cleaning techniques that can be used in the cloud hosted environments. In addition, we introduce the audience to distributed data repositories providing details about how data is stored across multiple nodes, how is indexed, and how data is retrieven on queries.

* Deploying your Data Analytics and Machine Learning Environment

In this section, we provide a guided hands-on tutorial in which each attendee will have the opportunity to create its own Big Data and Machine Learning environment in the cloud. The students will taught about the infrastructure we seek to deploy, the role of each installed tool, and their proper usage. Some of the tools we cover in this section are: elasticsearch, kibana, logstash, nginx, ufw, beats, kibana, and X-Pack for machine learning. 

* Deriving Structure from Unstructured Data

In this section, we present students with various approaches they can use to derive structure from unstructured data. The students will be guided through hands-on excersices in which they will be generating rules for pre-processing data obtained from different data shippers. In addition, the students will learn how to upload their own data through the API and Python.

* Querying and Filtering Your Data

In this section students will learn how to make queries to their data repository using Kibana's dashboard and Python. The students will be guided on how to use Python libraries to query, store data in JSON and Pandas data drames, and manipulate data in both formats for further processing.

* Data Visualization

This section covers the usage of Kibana's visualization tools. The students will learn how to use raw and pre-processed data to generate informative graphics using different tools within Kibana such as Canvas.

* Machine Learning

In this final section, students will be given a brief introduction on how to use X-pack's machine learning module. Each student will have the oportunity to train their model, visualize anomalies, and set alams when an anomaly is detected.
